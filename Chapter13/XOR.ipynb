{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>XOR Project</center><h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "- This project aims to solve the classical XOR problem by using the machine learning based methods with Pytorch.\n",
    "\n",
    "### Problem Definition\n",
    "- Dataset: 200 training examples, 100 validation examples, 100 test examples\n",
    "- Each example contains 2 features drawn from the unifrom distribution between [-1, 1)\n",
    "- The label is 0 if the product between 2 features is smaller than 0 else 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Train Dataset: 1, Validation Dataset: 2, Test Dataset: 3\n",
    "\n",
    "def generateDataLoader(size:int, batchSize:int, featureNumber:int, seed:int) -> DataLoader:\n",
    "    '''\n",
    "        By default, all dataloader uses shuffling for better performance\n",
    "    '''\n",
    "    dataset, label = generateNumpyDataset(size, featureNumber, seed)\n",
    "    dataset, label = torch.tensor(dataset, dtype=torch.float32), torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "    tensorDataset = TensorDataset(dataset, label)\n",
    "\n",
    "    return DataLoader(tensorDataset, batchSize, shuffle=True)\n",
    "\n",
    "def generateNumpyDataset(size:int, featureNumber:int, seed:int) -> tuple[np.ndarray, np.ndarray]:\n",
    "    '''\n",
    "        Return a dataset that is sampled from the uniform distribution bewteen -1 and 1\n",
    "    '''\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    data = np.random.uniform(-1, 1, (size, featureNumber))\n",
    "    label = np.ones(size)\n",
    "    label[data[:,0]*data[:,1] < 0] = 0\n",
    "\n",
    "    return data, label\n",
    "\n",
    "def plotNumpyDataset(data:np.ndarray, label:np.ndarray, title:str):\n",
    "    '''\n",
    "        Plot the dataset using different symbols for different classes\n",
    "    '''\n",
    "    figure = plt.figure(figsize=(6,6))\n",
    "\n",
    "    plt.scatter(data[label==0, 0], data[label==0, 1], marker=\"o\", alpha=0.75)\n",
    "    plt.scatter(data[label==1, 0], data[label==1, 1], marker=\"x\", alpha=0.75)\n",
    "\n",
    "    plt.xlabel(r\"$X_1$\")\n",
    "    plt.ylabel(r\"$X_2$\")\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "data, label = generateNumpyDataset(100, 2, 1)\n",
    "plotNumpyDataset(data, label, \"Random Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pytorch Model\n",
    "- The model is consisted of 3 linear layers (with ReLU activation function) + the final Sigmoid layer as output layer\n",
    "- A small zero-mean Gaussian noise is added at the first layer to regularise the model and avoid the overfitting problem only during the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "class NoisyLinear(nn.Module):\n",
    "    '''\n",
    "        Customized initialisation + noise during the training\n",
    "    '''\n",
    "    def __init__(self, inputFeature:int, outputFeature:int, noiseSTD:float):\n",
    "        super().__init__()\n",
    "\n",
    "        self.weight = nn.Parameter(self.constructWeight(inputFeature, outputFeature))\n",
    "        self.offset = nn.Parameter(self.constructOffset(outputFeature))\n",
    "        self.noiseSTD = noiseSTD\n",
    "    \n",
    "    def forward(self, input:torch.Tensor, training:bool=False) -> torch.Tensor:\n",
    "        '''\n",
    "            Only add a random zero-mean Gaussain noise to the input during the training process\n",
    "        '''\n",
    "        if training:\n",
    "            noise = torch.normal(0, self.noiseSTD, input.shape)\n",
    "            input = torch.add(input, noise)\n",
    "        \n",
    "        return torch.add(torch.mm(input, self.weight), self.offset)\n",
    "    \n",
    "    def constructWeight(self, inputFeature:int, outputFeature:int) -> torch.Tensor:\n",
    "        '''\n",
    "            By default, the weight of the layer is initialised by xavier uniform\n",
    "        '''\n",
    "        weight = torch.Tensor(inputFeature, outputFeature)\n",
    "        nn.init.xavier_uniform_(weight)\n",
    "\n",
    "        return weight\n",
    "    \n",
    "    def constructOffset(self, outputFeature:int) -> torch.Tensor:\n",
    "        '''\n",
    "            By default, the offset of the layer is initilised by filling 0\n",
    "        '''\n",
    "        offset = torch.Tensor(outputFeature).fill_(0)\n",
    "\n",
    "        return offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "class NoisyModel(nn.Module):\n",
    "    '''\n",
    "        3 (Linear + ReLU) + Sigmoid\n",
    "    '''\n",
    "    def __init__(self, inputFeature:int, outputFeature:int, noiseSTD:float):\n",
    "        super(NoisyModel, self).__init__()\n",
    "\n",
    "        self.noisyLayer = NoisyLinear(inputFeature, inputFeature*2, noiseSTD)\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(inputFeature*2, inputFeature*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(inputFeature*2, outputFeature),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, input:torch.Tensor, training:bool=False) -> torch.Tensor:\n",
    "        result = self.noisyLayer(input, training)\n",
    "        result = self.layer(result)\n",
    "\n",
    "        return result.flatten()\n",
    "    \n",
    "    def predict(self, input:np.ndarray) -> torch.Tensor:\n",
    "        input = torch.from_numpy(input).float()\n",
    "        result = self.forward(input)\n",
    "\n",
    "        return (result >= 0.5 ).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Experiment\n",
    "- Epoch: 200\n",
    "- Batch Size: 2, the size of the dataset is too small => requires a small batch size for more gradient calculation and update\n",
    "- Learning Rate: 1e-3, try a small learning rate first to work with a small batch size\n",
    "- Optimizer: Adam, auto adapted learning rate for better training process\n",
    "- Loss: Binary Cross Entropy Loss, very suitable for 2-class classification problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "def validateBatch(\n",
    "    validationLossBatchTotal:float,\n",
    "    validationAccuracyBatchTotal:float,\n",
    "    validationDataBatch:torch.Tensor,\n",
    "    validationLabelBatch:torch.Tensor,\n",
    "    model:NoisyModel,\n",
    "    loss:nn.BCELoss\n",
    ") -> tuple[float, float]:\n",
    "    return\n",
    "\n",
    "def trainBatch(\n",
    "    trainLossBatchTotal:float,\n",
    "    trainAccuracyBatchTotal:float,\n",
    "    trainDataBatch:torch.Tensor,\n",
    "    trainLabelBatch:torch.Tensor,\n",
    "    model:NoisyModel,\n",
    "    optimiser:Adam,\n",
    "    loss:nn.BCELoss\n",
    ") -> tuple[float, float]:\n",
    "    prediction = model.forward(trainDataBatch, True)\n",
    "\n",
    "    optimiser.zero_grad()\n",
    "    trainLossBatch = loss(prediction, trainLabelBatch)\n",
    "    trainLossBatch.backward()\n",
    "    optimiser.step()\n",
    "\n",
    "    trainLossBatchTotal += trainLossBatch.item()\n",
    "    trainAccuracyBatchTotal += ((prediction >= 0.5) == trainLabelBatch).float().mean()\n",
    "\n",
    "    return trainLossBatchTotal, trainAccuracyBatchTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "test = torch.tensor([0,0,1]).float()\n",
    "test2 = torch.tensor([1,0,1]).float()\n",
    "\n",
    "result = ((test >= 0.5).float() == test2)\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a3ea2dcf291eca603f1b3e1d1b828966eecb328a680036091e8db55ad6a767aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
